{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency counts for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts for 'Borough'\n",
    "print(df['Borough'].value_counts(dropna=False))\n",
    "\n",
    "# Print the value_counts for 'State'\n",
    "print(df['State'].value_counts(dropna=False))\n",
    "\n",
    "# Print the value counts for 'Site Fill'\n",
    "print(df['Site Fill'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing single variables with histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Describe the column\n",
    "df['Existing Zoning Sqft'].describe()\n",
    "\n",
    "# Plot the histogram\n",
    "df['Existing Zoning Sqft'].plot(kind='hist', rot=70, logx=True, logy=True)\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing multiple variables with boxplots\n",
    "\n",
    "#### In this exercise, your job is to use a boxplot to compare the 'initial_cost' across the different values of the 'Borough' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the boxplot\n",
    "df.boxplot(column='initial_cost', by='Borough', rot=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing multiple variables with scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create and display the first scatter plot\n",
    "df.plot(kind=\"scatter\", x='initial_cost', y='total_est_fee', rot=70)\n",
    "plt.show()\n",
    "\n",
    "# Create and display the second scatter plot\n",
    "df_subset.plot(kind=\"scatter\", x='initial_cost', y='total_est_fee', rot=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customizing melted data\n",
    "When melting DataFrames, it would be better to have column names more meaningful than variable and value (the default names used by pd.melt()).\n",
    "\n",
    "The default names may work in certain situations, but it's best to always have data that is self explanatory.\n",
    "\n",
    "You can rename the variable column by specifying an argument to the var_name parameter, and the value column by specifying an argument to the value_name parameter. You will now practice doing exactly this. Pandas as pd and the DataFrame airquality has been pre-loaded for you.\n",
    "\n",
    "Print the head of airquality.\n",
    "#### Melt the columns of airquality with the default variable column renamed to 'measurement' and the default value column renamed to 'reading'. You can do this by specifying, respectively, the var_name and value_name parameters.\n",
    "Print the head of airquality_melt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(airquality, id_vars=['Month', 'Day'], var_name=\"measurement\", value_name=\"reading\")\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "\n",
    "\n",
    "\n",
    "# change the name of variable and the value to measurement and reading respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot data\n",
    "Pivoting data is the opposite of melting it. Remember the tidy form that the airquality DataFrame was in before you melted it? You'll now begin pivoting it back into that form using the .pivot_table() method!\n",
    "\n",
    "While melting takes a set of columns and turns it into a single column, pivoting will create a new column for each unique value in a specified column.\n",
    "\n",
    ".pivot_table() has an index parameter which you can use to specify the columns that you don't want pivoted: It is similar to the id_vars parameter of pd.melt(). Two other parameters that you have to specify are columns (the name of the column you want to pivot), and values (the values to be used when the column is pivoted). The melted DataFrame airquality_melt has been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "\n",
    "# Pivot airquality_melt: airquality_pivot\n",
    "airquality_pivot = airquality_melt.pivot_table(index=[\"Month\", \"Day\"], columns=\"measurement\", values=\"reading\")\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting a column with .split() and .get()\n",
    "Another common way multiple variables are stored in columns is with a delimiter. You'll learn how to deal with such cases in this exercise, using a dataset consisting of Ebola cases and death counts by state and country. It has been pre-loaded into a DataFrame as ebola.\n",
    "\n",
    "Print the columns of ebola in the IPython Shell using ebola.columns. Notice that the data has column names such as Cases_Guinea and Deaths_Guinea. Here, the underscore _ serves as a delimiter between the first part (cases or deaths), and the second part (country).\n",
    "\n",
    "This time, you cannot directly slice the variable by position as in the previous exercise. You now need to use Python's built-in string method called .split(). By default, this method will split a string into parts separated by a space. However, in this case you want it to split by an underscore. You can do this on 'Cases_Guinea', for example, using 'Cases_Guinea'.split('_'), which returns the list ['Cases', 'Guinea'].\n",
    "\n",
    "The next challenge is to extract the first element of this list and assign it to a type variable, and the second element of the list to a country variable. You can accomplish this by accessing the str attribute of the column and using the .get() method to retrieve the 0 or 1 index, depending on the part you want.\n",
    "\n",
    "Melt ebola using 'Date' and 'Day' as the id_vars, 'type_country' as the var_name, and 'counts' as the value_name.\n",
    "\n",
    "Create a column called 'str_split' by splitting the 'type_country' column of ebola_melt on '_'. Note that you will first have to access the str attribute of type_country before you can use .split().\n",
    "\n",
    "Create a column called 'type' by using the .get() method to retrieve index 0 of the 'str_split' column of ebola_melt.\n",
    "\n",
    "Create a column called 'country' by using the .get() method to retrieve index 1 of the 'str_split' column of ebola_melt.\n",
    "\n",
    "Print the head of ebola_melt. This has been done for you, so hit 'Submit Answer' to view the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt ebola: ebola_melt\n",
    "ebola_melt = pd.melt(ebola, id_vars=[\"Date\", \"Day\"], var_name=\"type_country\", value_name=\"counts\")\n",
    "\n",
    "# Create the 'str_split' column\n",
    "ebola_melt['str_split'] = ebola_melt['type_country'].str.split('_')\n",
    "\n",
    "# # Create the 'type' column\n",
    "ebola_melt['type'] = ebola_melt['str_split'].str.get(0)\n",
    "\n",
    "# # Create the 'country' column\n",
    "ebola_melt['country'] = ebola_melt['str_split'].str.get(1)\n",
    "\n",
    "# Print the head of ebola_melt\n",
    "print(ebola_melt.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1, uber2,uber3])\n",
    "\n",
    "# Print the shape of row_concat\n",
    "print(row_concat.shape)\n",
    "\n",
    "# Print the head of row_concat\n",
    "print(row_concat.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining columns of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "ebola_tidy = pd.concat([ebola_melt, status_country], axis = 1)\n",
    "\n",
    "# Print the shape of ebola_tidy\n",
    "print(ebola_tidy.shape)\n",
    "\n",
    "# Print the head of ebola_tidy\n",
    "print(ebola_tidy.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding files that match a pattern\n",
    "You're now going to practice using the glob module to find all csv files in the workspace. In the next exercise, you'll programmatically load them into DataFrames.\n",
    "\n",
    "As Dan showed you in the video, the glob module has a function called glob that takes a pattern and returns a list of the files in the working directory that match that pattern.\n",
    "\n",
    "For example, if you know the pattern is part_ single digit number .csv, you can write the pattern as 'part_?.csv' (which would match part_1.csv, part_2.csv, part_3.csv, etc.)\n",
    "\n",
    "Similarly, you can find all .csv files with '*.csv', or all parts with 'part_*'. The ? wildcard represents any 1 character, and the * wildcard represents any number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern = '*.csv'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Print the file names\n",
    "print(csv_files)\n",
    "\n",
    "# Load the second file into a DataFrame: csv2\n",
    "csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# Print the head of csv2\n",
    "print(csv2.head())\n",
    "\n",
    "\n",
    "# Create an empty list: frames\n",
    "frames = []\n",
    "\n",
    "#  Iterate over csv_files\n",
    "for csv in csv_files:\n",
    "\n",
    "    #  Read csv into a DataFrame: df\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Append df to frames\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate frames into a single DataFrame: uber\n",
    "uber = pd.concat(frames)\n",
    "\n",
    "# Print the shape of uber\n",
    "print(uber.shape)\n",
    "\n",
    "# Print the head of uber\n",
    "print(uber.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge \n",
    "the site and visited DataFrames on the 'name' column of site and 'site' column of visited.\n",
    "Print the merged DataFrame o2o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on=\"name\", right_on=\"site\")\n",
    "\n",
    "# Print o2o\n",
    "print(o2o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
